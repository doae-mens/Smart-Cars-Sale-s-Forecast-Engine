import time
import pandas as pd
import numpy as np
import math
from matplotlib import pyplot as plt
%matplotlib inline  

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense, LSTM
from sklearn.preprocessing import MinMaxScaler

from pmdarima import auto_arima
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.seasonal import seasonal_decompose
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller, kpss, acf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

from datetime import datetime, timedelta

import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import re
import nltk
import spacy
import matplotlib.pyplot as plt
import seaborn as sns

%matplotlib inline

root_path = 'Databases/'
data  = pd.read_csv(root_path + 'Tesla-sales.csv')

df = data
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')

df['sales'].astype('float')
scaler= MinMaxScaler()
df[["sales"]] = scaler.fit_transform(df[["sales"]])

train = df.iloc[:3164]
test = df.iloc[3164:]
fig, ax = plt.subplots(figsize=(12,6))
train["sales"].plot(legend=True, label='Train',ax=ax)
test["sales"].plot(legend=True, label='Test',ax=ax);

data =np.array(df)
x=[]
y=[]
for i in range(60,len(data)):
    x.append(data[i-60:i,1])
    y.append(data[i,1])
        
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=len(test) , random_state=42,  shuffle=False)
x_train,y_train=np.array(x_train),np.array(y_train)
x_test,y_test=np.array(x_test),np.array(y_test)
x_train=np.array(x_train)
x_train=np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))
x_test=np.array(x_test)
x_test=np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))
train_size = int(len(train))
train_dataset, test_dataset = df.iloc[:train_size], df.iloc[train_size:]

n_input = 60
n_features = 1
# define model
model = Sequential()
model.add(LSTM(units=240, return_sequences=False, input_shape=(n_input,n_features)))#100
model.add(Dense(40))#80
model.add(Dense(1))

#compile the model
model.fit(x_train, y_train, epochs = 60, batch_size = 365)#epochs 60
x_test=np.array(x_test)
x_test=np.reshape(x_test,(x_test.shape[0],x_test.shape[1],x_test.shape[2]))
training_data_len = int(len(train))
predictions=model.predict(x_test)
train=df[:training_data_len]
valid=df[-len(predictions):]
valid['Predictions']=predictions
valid['sales']=y_test

#visualise the data
plt.figure(figsize=(15,8))
plt.title("Predicted Value VS Real Value")
plt.xlabel('Date',fontsize=16)
plt.ylabel('Sales',fontsize=16)
plt.plot(valid[['sales','Predictions']])
plt.legend(['Values','Predictions'],loc='upper right',fontsize="large")
#plt.savefig(r'C:\Users\ikhla\Desktop\TheseDoctorat\Articles\Article1\APPLICATION\pic/predLSTM1.jpg', format='jpg', dpi=1000)
plt.show();

y_test=np.array(y_test)
predictions=np.reshape(predictions,(len(test),))
mape3 = np.sum(np.abs((predictions-y_test)/y_test))/len(y_test)*100
print("Le pourcentage d'erreur absolu moyen du mod√®le est : {:.4f} %".format(mape3))
